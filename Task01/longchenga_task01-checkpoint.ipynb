{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataWhale---异常探测学习研究回顾\n",
    "从自我研究方向出发-船舶的异常行为，对于异常的定义、探测方法、应用进行简要梳理。\n",
    "并完成其他学习任务。\n",
    "\n",
    "# 摘要\n",
    "异常探测是数据挖掘领域的一个重要研究内容，旨在从海量数据中挖掘不符合普适性规律、表现出“与众不同”特性的数据或模式，其在金融欺诈、公共卫生、极端气候事件发现、交通拥堵判别、环境污染监测等领域具有重\n",
    "要应用价值。为了更好地满足应用需求，发展性能更高、适应性更强的异常探测方法，从数据维度角度对于异常进行分类可以划分为典型的传统／空间／时空异常探测方法。按照传统的分类方式，异常探测方法可以分为三类：基于传统统计学的探测方法；基于集成检测方法以及现比较应用多的基于深度学习的检测方法。\n",
    "\n",
    "\n",
    "# 一、异常的定义\n",
    "2001年，Portnoy：“异常检测方法对正常数据建立模型，然后尝试检测观测数据中与正常模型的偏差”\n",
    "\n",
    "2008年，Roy:\"与正常相悖的即为异常\"\n",
    "\n",
    "2009年，Chandola：“异常定义为不符合预期正常行为的模式”\n",
    "\n",
    "总结：\n",
    "现有研究针对不同领域对于异常的定义各有细化，比如在海上交通领域对于传播行为的异常，定义为“船舶偏离其固定航线或违背历史行进规律的行为”。\n",
    "但是现有研究对于异常探测比较偏向黑盒子，大部分还是认为不符合模型训练的目标具有异常行为。\n",
    "\n",
    "\n",
    "# 二、探测方法及其优缺点\n",
    "\n",
    "![alt 属性](https://github.com/longchenga/Overview-of-Abnormal-Detection-/blob/main/1Overview/%E5%BC%82%E5%B8%B8%E5%88%86%E7%B1%BB.png)\n",
    "\n",
    "接下来以船舶异常行为探测为方向，对其进行方法梳理\n",
    "\n",
    "**2.1 基于传统统计学的异常探测方法**\n",
    "\n",
    "基于统计学的异常检测中，轨迹正常模型的形式是一种轨迹点的概率模型。\n",
    "其检测原理是判断输入数据是否符合已有的概率模型，认为正常的船舶轨迹数据在模型中则输出较高概率数值，如果该输入数据在该模型的概率值较低，则将其识别为异常。\n",
    "其中比较典型的算法有高斯混合模型(Gaussian Mixture Model, GMM)、核密度估计(Kernel Density Estimation, KDE)以及贝叶斯网络(Bayesian Network ,BN)。\n",
    "采用统计学的方法检测船舶的异常行为，其特征模型较好地对于船舶特征包括目标瞬时运动状态特征进行融合探测，但有效依赖于对给定的船舶轨迹数据所作的统计模型假设是否成立。\n",
    "其优点是统计学方法具有坚实的理论基础，当存在充分的船舶轨迹数据和所用的检测类型知识时，检测结果非常有效。\n",
    "缺点是计算开销依赖于所建立的模型，在使用简单的参数模型如高斯模型时，拟合参数所需要的时间是线性的，但是，使用复杂的模型时，确定最佳参数值通常需要多次迭代，比较耗时。\n",
    "\n",
    "**2.2 基于集成的检测方法**\n",
    "\n",
    "集成是提⾼数据挖掘算法精度的常⽤⽅法。集成⽅法将多个算法或多个基检测器的输出结合起来。其基本思想是⼀些算法在某些⼦集上表现很好，⼀些算法在其他⼦集上表现很好，然后集成起来使得输出更加鲁棒。\n",
    "集成⽅法与基于⼦空间⽅法有着天然的相似性，⼦空间与不同的点集相关，⽽集成⽅法使⽤基检测器来探索不同维度的⼦集，将这些基学习器集合起来。\n",
    "\n",
    "**2.3 基于深度学习检测方法**\n",
    "\n",
    "随着计算机性能的提高深度学习进一步发展，人工神经网络的主要任务是学习现实世界中内嵌的模型，使得所建立的模型与真实世界具备高度一致性，以实现相关应用的特定目标，在异常检测领域得到了成功的应用。\n",
    "基于神经网络的异常检测算法，主要是通过建立神经网络模型，再利用历史数据对网络进行训练，其将目标数据输入神经网络模型中，通过网络输出判断该数据是否异常。神经网络最大缺点之一是该过程非常模糊，通常被称为黑盒子。并且输入和输出神经元之间处理是不可理解的，不能为操作者提供解释或相关理由。另外，神经网络容易出现过拟合现象，若网络在学习阶段针对性过于严格，则类别边界附近数据分类准确度可能会下降。\n",
    "\n",
    "# 四、pyod的实例\n",
    "\n",
    "pyod官网:[pyod](https://pyod.readthedocs.io/en/latest/)\n",
    "\n",
    "pyodgit:[pyod github](https://github.com/yzhao062/pyod)\n",
    "\n",
    "**pyod介绍：【摘自官网】**\n",
    "\n",
    "PyOD是一个全面且可扩展的Python工具箱，用于检测多元数据中的异常对象。这个令人兴奋而又充满挑战的领域通常称为 异常值检测 或异常检测。从传统的LOF（SIGMOD 2000）到最新的COPOD（ICDM 2020），PyOD包括30多种检测算法。\n",
    "\n",
    "**PyOD具有以下特点：\n",
    "\n",
    "跨各种算法的统一API，详细文档和交互式示例。\n",
    "\n",
    "高级型号，其中包括来自scikit学习古典的人，最新的深学习方法，和一样COPOD新兴算法。\n",
    "\n",
    "尽可能使用numba和joblib通过JIT和并行化优化性能。\n",
    "\n",
    "与Python 2和3兼容。\n",
    "\n",
    "**以KNN为实例实现**\n",
    "\n",
    "我是第一次接触pyod库，在pyod github里面有关于Pyod所有算法的example 还是比较详细的，通过查看可以发现pyod其同时包含了对于数据做处理的函数【这个让我觉得非常的棒！】之前用到的算法KNN和PCA比较多。\n",
    "\n",
    "**KNN：**\n",
    "\n",
    "K最近邻（KNN，K-NearestNeighbor）分类算法，是比较经典的分类算法，是将数据集合中每一个记录进行分类的方法，属于懒惰性学习算法，只有当需要分类的向量到达时才开始构造泛化模型。 是数据挖掘分类技术中最简单的方法之一。 算法中的每个样本都可以用它最接近的K个邻近值来代表。\n",
    "\n",
    "**作为实现，我利用pyod库自带的knn算法和sklearn库自带的knn算法进行了对比：\n",
    "\n",
    "数据集：iris数据集\n",
    "\n",
    "评价指标：sklearn自带函数库\n",
    "\n",
    "结果：sklearn结果更好【大概是因为我最近时间有点仓促没有对代码进行细看 可能后面会再仔细研究一下 因为精度差别有点大哈哈哈】 评价函数用的是sklearn自带的函数【precision_score】 pyod最后精度是0.3 sklearn是0.9 后续会再看是不是和数据集以及参数设置有关系~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.utils.example import visualize\n",
    "\n",
    "def get_iris():\n",
    "    from sklearn.datasets import load_iris\n",
    "    iris_data = load_iris()\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.4, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    contamination = 0.1  # percentage of outliers\n",
    "    n_train = 200  # number of training points\n",
    "    n_test = 100  # number of testing points\n",
    "\n",
    "    # Generate sample data\n",
    "    # X_train, y_train, X_test, y_test = \\\n",
    "    #     generate_data(n_train=n_train,\n",
    "    #                   n_test=n_test,\n",
    "    #                   n_features=2,\n",
    "    #                   contamination=contamination,\n",
    "    #                   random_state=42)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = get_iris()\n",
    "\n",
    "    # train kNN detector\n",
    "    clf_name = 'KNN'\n",
    "    clf = KNN()\n",
    "    clf.fit(X_train)\n",
    "\n",
    "    # get the prediction labels and outlier scores of the training data\n",
    "    y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "    y_train_scores = clf.decision_scores_  # raw outlier scores\n",
    "\n",
    "    # get the prediction on the test data\n",
    "    y_test_pred = clf.predict(X_test)  # outlier labels (0 or 1)\n",
    "    y_test_scores = clf.decision_function(X_test)  # outlier scores\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accu_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "    accu = precision_score(y_test, y_test_pred, average='micro')\n",
    "    print('pyod的准确率: ', accu)\n",
    "    # accu_train = accuracy_score(y_train, y_train_pred)\n",
    "    # evaluate and print the results\n",
    "    # print(\"\\nOn Training Data:\")\n",
    "    # evaluate_print(clf_name, y_train, y_train_scores)\n",
    "    # print(\"\\nOn Test Data:\")\n",
    "    # evaluate_print(clf_name, y_test, y_test_scores)\n",
    "    #\n",
    "    # # visualize the results\n",
    "    # visualize(clf_name, X_train, y_train, X_test, y_test, y_train_pred,\n",
    "    #           y_test_pred, show_figure=True, save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn的准确率:  0.95\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_iris():\n",
    "    iris_data = load_iris()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.4, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def knn_classify(self_point, dataset, labels, k):\n",
    "    distance = [np.sqrt(sum((self_point - d)**2)) for d in dataset]\n",
    "    train_data = zip(distance, labels)\n",
    "    train_data = sorted(train_data, key=lambda x: x[0])[:k]\n",
    "    self_label = {}\n",
    "    for i in train_data:\n",
    "        i = str(i[1])\n",
    "        self_label[i] = self_label.setdefault(i, 0) + 1\n",
    "    self_label = sorted(self_label, key=self_label.get, reverse=True)\n",
    "    return self_label[0]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_iris()\n",
    "size = len(y_test)\n",
    "count = 0\n",
    "for t in range(len(X_test)):\n",
    "    y_pre = knn_classify(X_test[t], X_train, y_train, 5)\n",
    "    if y_pre == str(y_test[t]):\n",
    "        count += 1\n",
    "# print('custom的准确率： ', count / size)\n",
    "\n",
    "# 使用sklearn内置的KNN\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "pre = knn.predict(X_test)\n",
    "# print('sklearn的准确率: ', accuracy_score(y_test, pre))\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "accu = precision_score(y_test, pre, average='micro')\n",
    "print('sklearn的准确率: ', accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
